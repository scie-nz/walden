coordinator=$${ENV:CONFIG_COORDINATOR}
node-scheduler.include-coordinator=false

# We listen on a different port to avoid issues around running as non-root
http-server.http.port=8080
# Meanwhile the 'trino' coordinator service is at port 80
discovery.uri=http://trino

# This is the max amount of user memory a query can use on a worker.
# Default: JVM max memory * 0.3
query.max-memory-per-node=${query_max_memory_per_node}
# This is the max amount of user memory a query can use across the entire cluster.
# Default: 20GB
query.max-memory=${query_max_memory}
# This is the amount of memory set aside as headroom/buffer in the JVM heap
# for allocations that are not tracked by Trino.
memory.heap-headroom-per-node=${memory_heap_headroom_per_node}
# (EXPERIMENTAL) This is the max amount of the memory a task can use on a node in the cluster.
# Default: unrestricted
#query.max-memory-per-task=4000MB

# TODO(nick): consider disabling spill and the /data PV in general, instead pointing node.data-dir to an emptyDir volume
# "spill"/swap disk storage for intermediate storage of queries
spill-enabled=true
spill-compression-enabled=true
# Directory where any spilled content is written.
# This is on local disk - we put it in a persistent volume.
spiller-spill-path=/data/trino/spill
# Max spill space to be used by all queries on a single node.
max-spill-per-node=${max_spill_per_node}
# Max spill space to be used by a single query on a single node.
query-max-spill-per-node=${query_max_spill_per_node}

# Increase caps on row size 8x. This may reduce errors like
# "PageTooLargeException: Remote page is too large" when handling large arrays.
# See also https://github.com/trinodb/trino/issues/10292
# default 16MB:
node-manager.http-client.max-content-length=128MB
# default 32MB:
exchange.http-client.max-content-length=256MB

# The number of concurrent writer threads per worker per query.
# Default: 1
task.writer-count=2
