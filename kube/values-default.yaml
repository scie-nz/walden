# These are the default settings for starting a new Walden instance.
# To customize these options:
# 1. Make a copy of this file
# 2. Edit the copy
# 3. Deploy with "./deploy.sh <myvalues.yaml>"

image:
  # Utility image for initContainers: config templating, waiting for dependencies to start.
  busybox: docker.io/library/busybox:latest
  minio: docker.io/minio/minio:RELEASE.2022-02-05T04-40-59Z
  # Changes to the Postgres major version require manually upgrading the on-disk data.
  postgres: docker.io/library/postgres:14.1
  redis: docker.io/library/redis:6.2.6-buster

  # The latest release versions for Walden images.
  # See walden/docker/* for image definitions.
  devserver: docker.io/scienz/walden-devserver:2022.02.25
  metastore: docker.io/scienz/walden-metastore:2022.02.08
  superset: docker.io/scienz/walden-superset:2022.02.10
  trino: docker.io/scienz/walden-trino:2022.02.25

minio:
  # The number of Minio replicas, must be at least four
  replicas: 4
  # The CPU architecture for Minio nodes, each must be running the same arch
  arch: amd64
  # The memory limit for each Minio pod.
  # Minio recommends 8GB for pods with up to 1TB storage/pod, or 16GB for up to 10TB storage/pod.
  # We start with very low values, increase to fit your system and workloads.
  mem_limit: 512Mi

superset:
  # The username/password for logging in to Superset
  # If either is empty, a random value is generated and stored in the "superset-admin" secret
  # This only takes effect during initial install. If you want to change it later,
  # edit the "superset-admin" Secret directly and restart the Superset pod.
  username: "walden"
  password: ""
  # Number of celery worker replicas.
  worker_replicas: 1
  # The memory limits for each of the Superset pods
  # We start with very low values, increase to fit your system and workloads.
  mem_limit_server: 1Gi
  mem_limit_worker: 1Gi
  # An external IP for the Superset service
  external_ip: ""

trino:
  # Number of worker replicas. By default the workers avoid colocating with the coordinator.
  worker_replicas: 1
  # The memory limits for each of the Trino pods
  # We start with very low values, increase to fit your system and workloads.
  mem_limit_coordinator: 2Gi
  mem_limit_worker: 2Gi
  # The value of "-Xmx" provided to the JVM
  mem_jvm_heap: 1536M
  # Disk storage for "spill" storage as configured below
  disk_worker: 25Gi
  # An external IP for the Trino service
  external_ip: ""

  # Settings for trino_config.properties
  # We start with very low values, increase to fit your system and workloads.
  config:
    # Note: query.max-memory-per-node + memory.heap-headroom-per-node cannot be larger than mem_jvm_heap
    # query.max-memory-per-node (default: mem_jvm_heap * 0.3)
    query_max_memory_per_node: 1024MB
    # memory.heap-headroom-per-node (default: mem_jvm_heap * 0.3)
    memory_heap_headroom_per_node: 512MB
    # query.max-memory (default: 20GB)
    query_max_memory: 4GB
    # max-spill-per-node and query-max-spill-per-node (disk space, default: 100GB)
    max_spill_per_node: 25GB
    query_max_spill_per_node: 10GB

  # Custom external data source to include in Trino connectors
  # See also: https://trino.io/docs/current/connector.html
  #catalog_custom: |
  #  connector.name=postgresql
  #  connection-url=jdbc:postgresql://example.com:5432/dbname
  #  connection-user=postgresUserHere
  #  connection-password=postgresPasswordHere
